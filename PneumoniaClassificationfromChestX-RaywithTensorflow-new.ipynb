{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the necessary libraries\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "from keras import optimizers\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path variables\n",
    "path_train_normal = r\"C:\\Users\\nikhil\\Documents\\Datasets\\chest_xray\\train\\NORMAL\"\n",
    "path_train_pnem = r\"C:\\Users\\nikhil\\Documents\\Datasets\\chest_xray\\train\\PNEUMONIA\"\n",
    "\n",
    "path_val_normal = r\"C:\\Users\\nikhil\\Documents\\Datasets\\chest_xray\\val\\NORMAL\"\n",
    "path_val_pnem = r\"C:\\Users\\nikhil\\Documents\\Datasets\\chest_xray\\val\\PNEUMONIA\"\n",
    "\n",
    "path_test_normal = r\"C:\\Users\\nikhil\\Documents\\Datasets\\chest_xray\\test\\NORMAL\"\n",
    "path_test_pnem = r\"C:\\Users\\nikhil\\Documents\\Datasets\\chest_xray\\test\\PNEUMONIA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variables to hold the number of jpegs in the directory\n",
    "\n",
    "count_jpeg_normal = len(glob.glob1(path_train_normal,\"*.jpeg\"))\n",
    "count_jpeg_pneum = len(glob.glob1(path_train_pnem,\"*.jpeg\"))\n",
    "\n",
    "count_jpeg_normal_val = len(glob.glob1(path_val_normal,\"*.jpeg\"))\n",
    "count_jpeg_pneum_val = len(glob.glob1(path_val_pnem,\"*.jpeg\"))\n",
    "\n",
    "count_jpeg_normal_test = len(glob.glob1(path_test_normal,\"*.jpeg\"))\n",
    "count_jpeg_pneum_test = len(glob.glob1(path_test_pnem,\"*.jpeg\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"NORMAL - Training {count_jpeg_normal} \\nPNEUMONIA - Training {count_jpeg_pneum} \\nNORMAL - Validation {count_jpeg_normal_val} \\nPNEUMONIA - Validation {count_jpeg_pneum_val} \\nNORMAL - Test {count_jpeg_normal_test} \\nPNEUMONIA - Test {count_jpeg_pneum_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the width, height and the dimensions - its use will come next, during resizing the images\n",
    "width = 128\n",
    "height = 128\n",
    "dim = (width, height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Collecting the images and resizing - NORMAL (takes a bit)\n",
    "images_NORMAL = []\n",
    "dim = (width, height)\n",
    "for i in range(count_jpeg_normal):\n",
    "    img = cv2.imread(path_train_normal +\"/\"+ str(glob.glob1(path_train_normal,\"*.jpeg\")[i]))\n",
    "    img = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
    "    images_NORMAL.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shape of images\n",
    "np.array(images_NORMAL).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_NORMAL are the patients that do not have PNEUMONIA\n",
    "y_NORMAL = np.zeros(np.array(images_NORMAL).shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_NORMAL.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Collecting the images and resizing - PNEUMONIA (takes a bit more)\n",
    "images_PNEUMONIA = []\n",
    "dim = (width, height)\n",
    "for j in range(count_jpeg_pneum):\n",
    "    img = cv2.imread(path_train_pnem +\"/\"+ str(glob.glob1(path_train_pnem,\"*.jpeg\")[j]))\n",
    "    img = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
    "    images_PNEUMONIA.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shape of images\n",
    "np.array(images_PNEUMONIA).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_NORMAL are the patients that have PNEUMONIA\n",
    "y_PNEUMONIA = np.ones(np.array(images_PNEUMONIA).shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_PNEUMONIA.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenating the NORMAL and PNEUMONIA arrays (independent variables)\n",
    "X = np.concatenate([np.array(images_NORMAL), np.array(images_PNEUMONIA)], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del images_NORMAL, images_PNEUMONIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Concatenating the predicted values of NORMAL and PNEUMONIA arrays (dependent variables)\n",
    "Y = np.concatenate([np.array(y_NORMAL), np.array(y_PNEUMONIA)], axis = 0).T # the .T is to get the transpose of the matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del y_NORMAL, y_PNEUMONIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variable that holds the number of classes to predict\n",
    "classes_to_predict = pd.Series(Y.tolist()).value_counts().count()\n",
    "print(classes_to_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Collecting the images and resizing - NORMAL - Validation set (almost instant)\n",
    "images_NORMAL_validation = []\n",
    "dim = (width, height)\n",
    "for k in range(count_jpeg_normal_val):\n",
    "    img = cv2.imread(path_val_normal +\"/\"+ str(glob.glob1(path_val_normal,\"*.jpeg\")[k]))\n",
    "    img = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
    "    images_NORMAL_validation.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(images_NORMAL_validation).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_val_NORMAL = np.zeros(np.array(images_NORMAL_validation).shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Collecting the images and resizing - PNEUMONIA - Validation set (almost instant too)\n",
    "images_PNEUMONIA_validation = []\n",
    "dim = (width, height)\n",
    "for l in range(count_jpeg_pneum_val):\n",
    "    img = cv2.imread(path_val_pnem +\"/\"+ str(glob.glob1(path_val_pnem,\"*.jpeg\")[l]))\n",
    "    img = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
    "    images_PNEUMONIA_validation.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(images_PNEUMONIA_validation).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_val_PNEUMONIA = np.ones(np.array(images_PNEUMONIA_validation).shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenating indepedent variables of the validation dataset\n",
    "X_VAL = np.concatenate([images_NORMAL_validation, images_PNEUMONIA_validation], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del images_NORMAL_validation, images_PNEUMONIA_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenating depedent variables of the validation dataset\n",
    "Y_VAL = np.concatenate([Y_val_NORMAL, Y_val_PNEUMONIA], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del Y_val_NORMAL, Y_val_PNEUMONIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building the model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(\n",
    "    Conv2D(\n",
    "        32, \n",
    "        kernel_size = (5, 5), \n",
    "        strides = (1, 1), \n",
    "        activation = 'relu', \n",
    "        input_shape = X.shape[1:]))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2)))\n",
    "          \n",
    "model.add(\n",
    "    Conv2D(\n",
    "        64, \n",
    "        (5, 5), \n",
    "        activation = 'relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(X.shape[1], activation = \"tanh\"))\n",
    "model.add(Dense(1000, activation = \"tanh\"))\n",
    "model.add(Dense(1000, activation = \"tanh\"))\n",
    "model.add(Dense(1000, activation = \"tanh\"))\n",
    "model.add(Dense(1000, activation = \"tanh\"))\n",
    "model.add(Dense(1000, activation = \"tanh\"))\n",
    "model.add(Dense(1000, activation = \"tanh\"))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss = \"binary_crossentropy\", optimizer = sgd, metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Re-resizing:\n",
    "X = X.astype('float32')\n",
    "X_VAL = X_VAL.astype('float32')\n",
    "X /= 255\n",
    "X_VAL /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelfit = model.fit(\n",
    "    X,\n",
    "    Y,\n",
    "    batch_size = 10,\n",
    "    epochs = 10,\n",
    "    verbose = 1,\n",
    "    validation_data = (X_VAL, Y_VAL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelfit.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(modelfit.history['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(modelfit.history['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(model.history.history['val_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('loss')\n",
    "plt.plot(model.history.history['acc'], model.history.history['loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(model.history.history['loss'])\n",
    "plt.plot(model.history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_VAL, Y_VAL, verbose = 0)\n",
    "print(f\"Validation loss: {score[0]}, Validation acc: {score[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_test_normal = r\"C:\\Users\\nikhil\\Documents\\Datasets\\chest_xray\\test\\NORMAL\"\n",
    "path_test_pnem = r\"C:\\Users\\nikhil\\Documents\\Datasets\\chest_xray\\test\\PNEUMONIA\"\n",
    "\n",
    "count_jpeg_normal_test = len(glob.glob1(path_test_normal,\"*.jpeg\"))\n",
    "count_jpeg_pneum_test = len(glob.glob1(path_test_pnem,\"*.jpeg\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Collecting the images and resizing - NORMAL - Test set\n",
    "images_NORMAL_test = []\n",
    "dim = (width, height)\n",
    "for i in range(count_jpeg_normal_test):\n",
    "    img = cv2.imread(path_test_normal +\"/\"+ str(glob.glob1(path_test_normal,\"*.jpeg\")[l]))\n",
    "    img = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
    "    images_NORMAL_test.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.asarray(images_NORMAL_test).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Collecting the images and resizing - PNEUMONIA - Test set\n",
    "images_PNEUMONIA_test = []\n",
    "dim = (width, height)\n",
    "for i in range(count_jpeg_pneum_test):\n",
    "    img = cv2.imread(path_test_pnem +\"/\"+ str(glob.glob1(path_test_pnem,\"*.jpeg\")[l]))\n",
    "    img = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
    "    images_PNEUMONIA_test.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.asarray(images_PNEUMONIA_test).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypredNORMAL = model.predict_classes(np.array(images_NORMAL_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypredPNEM = model.predict(np.array(images_PNEUMONIA_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(yPNEM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''https://machinelearningmastery.com/how-to-make-classification-and-regression-predictions-for-deep-learning-models-in-keras/\n",
    "https://github.com/adventuresinML/adventures-in-ml-code/blob/master/keras_cnn.py'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
